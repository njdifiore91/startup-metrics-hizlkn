# Logstash 7.17.0 Configuration
# Enhanced configuration for Startup Metrics Benchmarking Platform monitoring

# Global Settings
pipeline.workers: 2
pipeline.batch.size: 125
pipeline.batch.delay: 50
queue.type: persisted
queue.max_bytes: 1gb
path.data: /var/lib/logstash
log.level: info

# Input Section
input {
  beats {
    port => 5044
    host => "0.0.0.0"
    client_inactivity_timeout => 60
    ssl_enabled => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify_mode => "force_peer"
  }

  tcp {
    port => 5000
    codec => json
    ssl_enabled => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
  }

  http {
    port => 8080
    codec => json
    ssl_enabled => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    additional_codecs => ["plain", "json_lines"]
  }
}

# Filter Section
filter {
  # JSON Parsing
  json {
    source => "message"
    target => "parsed_json"
    skip_on_invalid_json => true
    remove_field => ["message"]
  }

  # Grok Pattern Matching
  grok {
    match => {
      "message" => [
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} \[%{DATA:service}\] \[%{DATA:correlation_id}\] %{GREEDYDATA:message}",
        "%{TIMESTAMP_ISO8601:timestamp} %{DATA:metric_name}=%{NUMBER:metric_value} host=%{DATA:host} service=%{DATA:service}",
        "%{TIMESTAMP_ISO8601:timestamp} ERROR \[%{DATA:service}\] \[%{DATA:error_code}\] \[%{DATA:correlation_id}\] %{GREEDYDATA:error_message}"
      ]
    }
    pattern_definitions => {
      "CUSTOM_TIMESTAMP" => "\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z"
    }
  }

  # Date Processing
  date {
    match => ["timestamp"]
    target => "@timestamp"
    timezone => "UTC"
    locale => "en"
  }

  # Field Mutations
  mutate {
    add_field => {
      "environment" => "%{[environment]}"
      "service" => "%{[service_name]}"
      "host_ip" => "%{[host][ip]}"
      "correlation_id" => "%{[trace][id]}"
    }
    convert => {
      "metric_value" => "float"
    }
  }

  # Error Log Processing
  if [log_level] == "ERROR" {
    mutate {
      add_tag => ["error"]
      add_field => {
        "error_severity" => "high"
        "alert_required" => "true"
      }
    }
  }

  # Metric Processing
  if [metric_name] {
    mutate {
      add_tag => ["metric"]
      add_field => {
        "metric_type" => "application"
        "collection_timestamp" => "%{@timestamp}"
      }
    }
  }
}

# Output Section
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "startup-metrics-%{+YYYY.MM.dd}"
    template_name => "startup-metrics"
    template_overwrite => true
    manage_template => true
    document_type => "_doc"
    retry_on_conflict => 3
    bulk_size => 5000
    flush_size => 500
    idle_flush_time => "1s"
    timeout => "30s"
  }

  # Development Debug Output
  if [environment] == "development" {
    stdout {
      codec => rubydebug
    }
  }

  # Error Alert Output
  if "error" in [tags] {
    http {
      url => "http://alert-service:8080/api/alerts"
      http_method => "post"
      format => "json"
      content_type => "application/json"
    }
  }
}